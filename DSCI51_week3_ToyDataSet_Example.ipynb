{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyPHfyM9drqanyuFTq9PSI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dornercr/DSCI511/blob/main/DSCI51_week3_ToyDataSet_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cuOnn4UcuOnq",
        "outputId": "1ac7c3ee-ca69-4364-b10c-13fb4f38bca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (1.0.2)\n"
          ]
        }
      ],
      "source": [
        "#pip install xmltodict\n",
        "\n",
        "from pprint import pprint\n",
        "import csv\n",
        "from io import StringIO\n",
        "import xmltodict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 2. Simulated Transit Arrivals (Bus API)\n",
        "# Real-time transit APIs often provide structured JSON data that includes\n",
        "# lists of arriving buses, their estimated arrival times, and status.\n",
        "# Here, we simulate 10,000 arrival entries and analyze them using pandas to\n",
        "# calculate wait time distributions, delayed percentages, and route frequency.\n",
        "# This models a realistic public transportation monitoring application.\n",
        "\n",
        "# %%\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Setup possible values\n",
        "bus_routes = ['Midtown Loop', 'Uptown Express', 'Suburban Shuttle', 'Airport Connector', 'City Circle']\n",
        "status_pool = ['On Time', 'Delayed', 'Cancelled']\n",
        "\n",
        "# Generate 10,000 fake bus arrival records\n",
        "bus_arrival_data = []\n",
        "for i in range(10000):\n",
        "    bus = {\n",
        "        'bus_number': f\"{random.randint(1, 99)}{random.choice(['A', 'B', 'C'])}\",\n",
        "        'route': random.choice(bus_routes),\n",
        "        'arrival_in_min': random.randint(1, 30),\n",
        "        'status': random.choices(status_pool, weights=[0.7, 0.25, 0.05])[0]\n",
        "    }\n",
        "    bus_arrival_data.append(bus)\n",
        "\n",
        "# Load into DataFrame\n",
        "bus_df = pd.DataFrame(bus_arrival_data)\n",
        "\n",
        "# === Data Analysis ===\n",
        "print(\"\\n=== Sample Bus Arrivals ===\")\n",
        "print(bus_df.head())\n",
        "\n",
        "print(\"\\n=== Status Counts ===\")\n",
        "print(bus_df['status'].value_counts())\n",
        "\n",
        "print(\"\\nAverage Arrival Time (min):\", bus_df['arrival_in_min'].mean())\n",
        "\n",
        "print(\"\\n=== Top Routes ===\")\n",
        "print(bus_df['route'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bJ_MYxRfuhMs",
        "outputId": "913f408d-30b9-4f21-aa4f-90f42487e143"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sample Bus Arrivals ===\n",
            "  bus_number              route  arrival_in_min   status\n",
            "0        30A   Suburban Shuttle              13  Delayed\n",
            "1        39C        City Circle              23  On Time\n",
            "2        77C     Uptown Express              17  On Time\n",
            "3        31B  Airport Connector              12  On Time\n",
            "4        96C        City Circle               1  Delayed\n",
            "\n",
            "=== Status Counts ===\n",
            "status\n",
            "On Time      7032\n",
            "Delayed      2484\n",
            "Cancelled     484\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Average Arrival Time (min): 15.407\n",
            "\n",
            "=== Top Routes ===\n",
            "route\n",
            "City Circle          2051\n",
            "Midtown Loop         2009\n",
            "Airport Connector    1992\n",
            "Uptown Express       1977\n",
            "Suburban Shuttle     1971\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 3. Simulated CSV Schedule (University Courses)\n",
        "# Many older APIs or internal systems return data in CSV format rather than JSON or XML.\n",
        "# In this section, we simulate a university’s course scheduling system that exports CSV data\n",
        "# about courses, professors, scheduled times, departments, and credits.\n",
        "# We generate 10,000 course records and then parse them using Python’s `csv` module and\n",
        "# `pandas` for analysis.\n",
        "# This section teaches how to work with tabular data exported from a system,\n",
        "# including filtering, aggregation, and cleanup.\n",
        "\n",
        "# %%\n",
        "import csv\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "departments = ['CS', 'MATH', 'PHYS', 'HIST', 'BIO', 'ENG', 'ECON']\n",
        "professors = ['Dr. Wu', 'Dr. Singh', 'Dr. Allen', 'Dr. Kim', 'Dr. Zhao', 'Dr. Thomas']\n",
        "times = ['8:00AM', '9:30AM', '11:00AM', '1:00PM', '2:30PM', '4:00PM']\n",
        "\n",
        "# Generate 10,000 rows of fake CSV data\n",
        "csv_lines = [\"Course,Professor,Time,Credits\"]\n",
        "for i in range(10000):\n",
        "    course_code = f\"{random.choice(departments)}{random.randint(100, 499)}\"\n",
        "    line = f\"{course_code},{random.choice(professors)},{random.choice(times)},{random.choice([3, 4])}\"\n",
        "    csv_lines.append(line)\n",
        "\n",
        "# Combine lines into one CSV string\n",
        "csv_data = \"\\n\".join(csv_lines)\n",
        "\n",
        "# Use StringIO to simulate reading from a CSV file\n",
        "f = StringIO(csv_data)\n",
        "reader = csv.reader(f)\n",
        "rows = list(reader)\n",
        "\n",
        "# Print first 3 rows (including header)\n",
        "print(\"=== Preview CSV Rows ===\")\n",
        "for row in rows[:4]:\n",
        "    print(row)\n",
        "\n",
        "# Load into DataFrame for analysis\n",
        "df_courses = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "\n",
        "# Convert credits to numeric\n",
        "df_courses['Credits'] = df_courses['Credits'].astype(int)\n",
        "\n",
        "# === Analysis ===\n",
        "print(\"\\n=== Most Common Courses ===\")\n",
        "print(df_courses['Course'].value_counts().head())\n",
        "\n",
        "print(\"\\n=== Credit Distribution ===\")\n",
        "print(df_courses['Credits'].value_counts())\n",
        "\n",
        "print(\"\\n=== Courses by Professor ===\")\n",
        "print(df_courses['Professor'].value_counts().head())\n",
        "\n",
        "print(\"\\n=== Scheduled Times ===\")\n",
        "print(df_courses['Time'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cluNfny5ujxg",
        "outputId": "9d5dc560-0415-4ee3-8470-01f71e21dbdc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Preview CSV Rows ===\n",
            "['Course', 'Professor', 'Time', 'Credits']\n",
            "['PHYS445', 'Dr. Thomas', '11:00AM', '3']\n",
            "['ECON393', 'Dr. Wu', '8:00AM', '3']\n",
            "['ENG254', 'Dr. Zhao', '8:00AM', '4']\n",
            "\n",
            "=== Most Common Courses ===\n",
            "Course\n",
            "CS377      13\n",
            "PHYS470    13\n",
            "PHYS496    11\n",
            "ECON238    11\n",
            "MATH128    11\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Credit Distribution ===\n",
            "Credits\n",
            "3    5014\n",
            "4    4986\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Courses by Professor ===\n",
            "Professor\n",
            "Dr. Allen     1745\n",
            "Dr. Kim       1723\n",
            "Dr. Thomas    1669\n",
            "Dr. Wu        1638\n",
            "Dr. Zhao      1626\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Scheduled Times ===\n",
            "Time\n",
            "2:30PM     1726\n",
            "8:00AM     1701\n",
            "11:00AM    1700\n",
            "4:00PM     1655\n",
            "1:00PM     1618\n",
            "9:30AM     1600\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 4. Simulated GeoJSON (Zoo Areas / City Blocks)\n",
        "# Geo-based APIs like OpenStreetMap or municipal datasets often provide boundaries in the form of GeoJSON,\n",
        "# which include coordinates that define the borders of regions such as parks, neighborhoods, or zoo enclosures.\n",
        "# In this section, we simulate 10,000 polygon boundaries — each representing a rectangular “zone”\n",
        "# (like a city block or animal enclosure).\n",
        "# This teaches students how polygon coordinates are structured, how to parse GeoJSON-style responses,\n",
        "# and how to extract bounding shapes from geospatial APIs.\n",
        "\n",
        "# %%\n",
        "import random\n",
        "\n",
        "# Generate 10,000 mock polygon zones\n",
        "geojson_data = []\n",
        "for i in range(10000):\n",
        "    lat_base = 39.90 + random.random() * 0.1  # Latitude around Philly\n",
        "    lon_base = -75.20 + random.random() * 0.1  # Longitude around Philly\n",
        "\n",
        "    polygon = {\n",
        "        'id': i,\n",
        "        'zone_name': f\"Zone_{i}\",\n",
        "        'geojson': {\n",
        "            'type': 'Polygon',\n",
        "            'coordinates': [[\n",
        "                [lon_base, lat_base],\n",
        "                [lon_base + 0.001, lat_base],\n",
        "                [lon_base + 0.001, lat_base + 0.001],\n",
        "                [lon_base, lat_base + 0.001],\n",
        "                [lon_base, lat_base]  # closing loop\n",
        "            ]]\n",
        "        }\n",
        "    }\n",
        "    geojson_data.append(polygon)\n",
        "\n",
        "# View first 2 polygon shapes\n",
        "from pprint import pprint\n",
        "print(\"=== Sample GeoJSON Zones ===\")\n",
        "pprint(geojson_data[:2])\n",
        "\n",
        "# Flatten for DataFrame analysis\n",
        "import pandas as pd\n",
        "flat_geo = []\n",
        "for zone in geojson_data:\n",
        "    coords = zone['geojson']['coordinates'][0]\n",
        "    flat_geo.append({\n",
        "        'id': zone['id'],\n",
        "        'zone_name': zone['zone_name'],\n",
        "        'min_lat': min(c[1] for c in coords),\n",
        "        'max_lat': max(c[1] for c in coords),\n",
        "        'min_lon': min(c[0] for c in coords),\n",
        "        'max_lon': max(c[0] for c in coords)\n",
        "    })\n",
        "\n",
        "geo_df = pd.DataFrame(flat_geo)\n",
        "\n",
        "print(\"\\n=== Bounding Box Summary ===\")\n",
        "print(geo_df.describe())\n",
        "\n",
        "print(\"\\nTotal unique zones:\", geo_df['zone_name'].nunique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Xig7IQC-xGEj",
        "outputId": "fa92dcf1-65d2-4233-eaaa-da910b0422a7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sample GeoJSON Zones ===\n",
            "[{'geojson': {'coordinates': [[[-75.18838001419057, 39.90937868345754],\n",
            "                               [-75.18738001419057, 39.90937868345754],\n",
            "                               [-75.18738001419057, 39.91037868345754],\n",
            "                               [-75.18838001419057, 39.91037868345754],\n",
            "                               [-75.18838001419057, 39.90937868345754]]],\n",
            "              'type': 'Polygon'},\n",
            "  'id': 0,\n",
            "  'zone_name': 'Zone_0'},\n",
            " {'geojson': {'coordinates': [[[-75.14232370380229, 39.993131274509416],\n",
            "                               [-75.14132370380229, 39.993131274509416],\n",
            "                               [-75.14132370380229, 39.994131274509414],\n",
            "                               [-75.14232370380229, 39.994131274509414],\n",
            "                               [-75.14232370380229, 39.993131274509416]]],\n",
            "              'type': 'Polygon'},\n",
            "  'id': 1,\n",
            "  'zone_name': 'Zone_1'}]\n",
            "\n",
            "=== Bounding Box Summary ===\n",
            "                id       min_lat       max_lat       min_lon       max_lon\n",
            "count  10000.00000  10000.000000  10000.000000  10000.000000  10000.000000\n",
            "mean    4999.50000     39.950670     39.951670    -75.150153    -75.149153\n",
            "std     2886.89568      0.029040      0.029040      0.028857      0.028857\n",
            "min        0.00000     39.900006     39.901006    -75.199998    -75.198998\n",
            "25%     2499.75000     39.925331     39.926331    -75.175030    -75.174030\n",
            "50%     4999.50000     39.951280     39.952280    -75.150443    -75.149443\n",
            "75%     7499.25000     39.975625     39.976625    -75.125127    -75.124127\n",
            "max     9999.00000     39.999988     40.000988    -75.100021    -75.099021\n",
            "\n",
            "Total unique zones: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 5. Simulated XML Feed (News Articles)\n",
        "# Some APIs — especially older ones, RSS feeds, or enterprise services — return structured text in XML format.\n",
        "# XML is hierarchical and tag-based, like HTML. This section simulates an XML news article feed with 10,000 articles,\n",
        "# each including a `headline`, `author`, and `content` tag.\n",
        "# We parse the XML using the `xmltodict` library, extract the text from each field, and perform basic text analysis.\n",
        "# This teaches students how to work with semi-structured formats and introduces parsing techniques\n",
        "# for systems where JSON is not available.\n",
        "\n",
        "# %%\n",
        "import xmltodict\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Fake authors and headlines\n",
        "authors = ['Alice Rivera', 'Michael Lee', 'Jenna Patel', 'Thomas Zhang', 'Maya Brooks']\n",
        "topics = ['Clean Energy', 'Elections', 'AI Regulation', 'Mars Mission', 'Education Reform']\n",
        "\n",
        "# Generate 10,000 fake XML articles\n",
        "xml_articles = []\n",
        "for i in range(10000):\n",
        "    xml_string = f\"\"\"\n",
        "    <article>\n",
        "        <headline>{random.choice(topics)} Bill #{i}</headline>\n",
        "        <author>{random.choice(authors)}</author>\n",
        "        <content>This is the full body text of article #{i}, detailing updates about {random.choice(topics)}.</content>\n",
        "    </article>\n",
        "    \"\"\"\n",
        "    xml_articles.append(xml_string)\n",
        "\n",
        "# Parse first 5 articles into Python dicts\n",
        "parsed_articles = []\n",
        "for x in xml_articles[:5]:\n",
        "    parsed = xmltodict.parse(x)\n",
        "    article = parsed['article']\n",
        "    parsed_articles.append(article)\n",
        "\n",
        "print(\"=== Sample Parsed Articles ===\")\n",
        "from pprint import pprint\n",
        "pprint(parsed_articles)\n",
        "\n",
        "# Load into DataFrame for further analysis\n",
        "article_df = pd.DataFrame(parsed_articles)\n",
        "print(\"\\n=== Sample DataFrame ===\")\n",
        "print(article_df.head())\n",
        "\n",
        "# Analyze most common authors\n",
        "print(\"\\n=== Author Frequency ===\")\n",
        "print(article_df['author'].value_counts())\n",
        "\n",
        "# Analyze word counts in content\n",
        "article_df['word_count'] = article_df['content'].str.split().apply(len)\n",
        "print(\"\\nAverage word count:\", article_df['word_count'].mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bOXVGkTaxLC4",
        "outputId": "2fe9b33f-925d-42bf-e3ca-bccbc365a4dc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sample Parsed Articles ===\n",
            "[{'author': 'Michael Lee',\n",
            "  'content': 'This is the full body text of article #0, detailing updates '\n",
            "             'about Education Reform.',\n",
            "  'headline': 'Education Reform Bill #0'},\n",
            " {'author': 'Alice Rivera',\n",
            "  'content': 'This is the full body text of article #1, detailing updates '\n",
            "             'about AI Regulation.',\n",
            "  'headline': 'Education Reform Bill #1'},\n",
            " {'author': 'Thomas Zhang',\n",
            "  'content': 'This is the full body text of article #2, detailing updates '\n",
            "             'about Education Reform.',\n",
            "  'headline': 'Elections Bill #2'},\n",
            " {'author': 'Alice Rivera',\n",
            "  'content': 'This is the full body text of article #3, detailing updates '\n",
            "             'about Mars Mission.',\n",
            "  'headline': 'Elections Bill #3'},\n",
            " {'author': 'Maya Brooks',\n",
            "  'content': 'This is the full body text of article #4, detailing updates '\n",
            "             'about Clean Energy.',\n",
            "  'headline': 'Education Reform Bill #4'}]\n",
            "\n",
            "=== Sample DataFrame ===\n",
            "                   headline        author  \\\n",
            "0  Education Reform Bill #0   Michael Lee   \n",
            "1  Education Reform Bill #1  Alice Rivera   \n",
            "2         Elections Bill #2  Thomas Zhang   \n",
            "3         Elections Bill #3  Alice Rivera   \n",
            "4  Education Reform Bill #4   Maya Brooks   \n",
            "\n",
            "                                             content  \n",
            "0  This is the full body text of article #0, deta...  \n",
            "1  This is the full body text of article #1, deta...  \n",
            "2  This is the full body text of article #2, deta...  \n",
            "3  This is the full body text of article #3, deta...  \n",
            "4  This is the full body text of article #4, deta...  \n",
            "\n",
            "=== Author Frequency ===\n",
            "author\n",
            "Alice Rivera    2\n",
            "Michael Lee     1\n",
            "Thomas Zhang    1\n",
            "Maya Brooks     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Average word count: 14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 6. Simulated Sports Stats (Basketball Match Data)\n",
        "# APIs that provide sports data often deliver complex, nested JSON structures with deeply connected entities:\n",
        "# teams, players, scores, and events. Services like Sportradar expose this data through authentication-based APIs.\n",
        "# In this simulation, we generate 10,000 basketball game summaries, including team names, home/away roles, final scores,\n",
        "# and top scorers. The exercise demonstrates parsing nested JSON objects, calculating team performance metrics,\n",
        "# and identifying trends (e.g., average point difference or high scorers).\n",
        "# This is foundational for sports analytics dashboards and event stream processing.\n",
        "\n",
        "# %%\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "teams = ['Lions', 'Tigers', 'Sharks', 'Wolves', 'Dragons', 'Falcons']\n",
        "players = ['Jordan Wells', 'Avery Black', 'Riley Chen', 'Chris Strong', 'Skylar Moore']\n",
        "\n",
        "# Generate 10,000 game records\n",
        "games = []\n",
        "for i in range(10000):\n",
        "    home_team = random.choice(teams)\n",
        "    away_team = random.choice([t for t in teams if t != home_team])\n",
        "    home_score = random.randint(70, 130)\n",
        "    away_score = random.randint(70, 130)\n",
        "    top_scorer = random.choice(players)\n",
        "    top_points = random.randint(20, 45)\n",
        "\n",
        "    game = {\n",
        "        'game_id': f\"game_{i}\",\n",
        "        'home_team': home_team,\n",
        "        'away_team': away_team,\n",
        "        'home_score': home_score,\n",
        "        'away_score': away_score,\n",
        "        'winner': home_team if home_score > away_score else away_team,\n",
        "        'top_scorer': top_scorer,\n",
        "        'points_scored': top_points\n",
        "    }\n",
        "    games.append(game)\n",
        "\n",
        "# Load into DataFrame\n",
        "game_df = pd.DataFrame(games)\n",
        "\n",
        "print(\"=== Sample Games ===\")\n",
        "print(game_df.head())\n",
        "\n",
        "# Calculate average point difference\n",
        "game_df['point_diff'] = abs(game_df['home_score'] - game_df['away_score'])\n",
        "print(\"\\nAverage Point Difference:\", game_df['point_diff'].mean())\n",
        "\n",
        "# Count team wins\n",
        "print(\"\\n=== Team Wins ===\")\n",
        "print(game_df['winner'].value_counts())\n",
        "\n",
        "# Top scorers by frequency\n",
        "print(\"\\n=== Frequent Top Scorers ===\")\n",
        "print(game_df['top_scorer'].value_counts())\n",
        "\n",
        "# Highest individual scoring performance\n",
        "max_points = game_df['points_scored'].max()\n",
        "print(\"\\n=== Max Points in a Game:\", max_points)\n",
        "print(game_df[game_df['points_scored'] == max_points])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b3x3NyNyxRTZ",
        "outputId": "0b9a43a3-ed9b-48d8-da75-f958e89feee2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sample Games ===\n",
            "  game_id home_team away_team  home_score  away_score   winner    top_scorer  \\\n",
            "0  game_0     Lions   Dragons         114         129  Dragons   Avery Black   \n",
            "1  game_1    Sharks   Dragons          72          99  Dragons  Chris Strong   \n",
            "2  game_2   Falcons     Lions         113         100  Falcons  Jordan Wells   \n",
            "3  game_3   Dragons    Tigers         104          76  Dragons  Skylar Moore   \n",
            "4  game_4   Falcons     Lions         119         130    Lions   Avery Black   \n",
            "\n",
            "   points_scored  \n",
            "0             21  \n",
            "1             36  \n",
            "2             22  \n",
            "3             20  \n",
            "4             29  \n",
            "\n",
            "Average Point Difference: 20.2475\n",
            "\n",
            "=== Team Wins ===\n",
            "winner\n",
            "Falcons    1709\n",
            "Sharks     1703\n",
            "Lions      1693\n",
            "Dragons    1674\n",
            "Wolves     1620\n",
            "Tigers     1601\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Frequent Top Scorers ===\n",
            "top_scorer\n",
            "Jordan Wells    2051\n",
            "Avery Black     2016\n",
            "Riley Chen      1991\n",
            "Skylar Moore    1975\n",
            "Chris Strong    1967\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Max Points in a Game: 45\n",
            "        game_id home_team away_team  home_score  away_score   winner  \\\n",
            "12      game_12   Dragons    Tigers         117          71  Dragons   \n",
            "42      game_42   Dragons   Falcons          98          94  Dragons   \n",
            "44      game_44     Lions   Falcons         110          97    Lions   \n",
            "60      game_60   Falcons    Sharks          98         118   Sharks   \n",
            "78      game_78    Tigers    Wolves          94          73   Tigers   \n",
            "...         ...       ...       ...         ...         ...      ...   \n",
            "9826  game_9826   Dragons   Falcons         121          72  Dragons   \n",
            "9844  game_9844     Lions    Sharks         113         115   Sharks   \n",
            "9863  game_9863    Tigers    Sharks          97         122   Sharks   \n",
            "9910  game_9910   Falcons   Dragons          83          74  Falcons   \n",
            "9999  game_9999    Wolves    Sharks          99         114   Sharks   \n",
            "\n",
            "        top_scorer  points_scored  point_diff  \n",
            "12    Skylar Moore             45          46  \n",
            "42    Skylar Moore             45           4  \n",
            "44    Skylar Moore             45          13  \n",
            "60    Jordan Wells             45          20  \n",
            "78      Riley Chen             45          21  \n",
            "...            ...            ...         ...  \n",
            "9826  Jordan Wells             45          49  \n",
            "9844  Skylar Moore             45           2  \n",
            "9863  Jordan Wells             45          25  \n",
            "9910  Chris Strong             45           9  \n",
            "9999   Avery Black             45          15  \n",
            "\n",
            "[395 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 7. Simulated Social Feed (Lab Journal Updates)\n",
        "# APIs like Twitter (or X) return chronological, short-form updates in a structured JSON format. These data streams are\n",
        "# excellent for time-series analysis, event monitoring, or content filtering. In this simulation, we generate 10,000\n",
        "# lab journal entries formatted like tweets — each with a timestamp and brief update text.\n",
        "# The focus here is on understanding how social/post feed APIs deliver real-time or recent items, and how to:\n",
        "# - Parse timestamped records\n",
        "# - Filter by keywords\n",
        "# - Count frequency of posts over time\n",
        "# This prepares students to work with social APIs, chat logs, or any time-stamped communications platform.\n",
        "\n",
        "# %%\n",
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Setup\n",
        "topics = ['protein folding', 'paper submission', 'experimental alignment', 'data cleanup', 'model training']\n",
        "people = ['Dr. Lee', 'Alex', 'Jordan', 'Casey', 'Ravi']\n",
        "\n",
        "# Generate timestamps over the past 90 days\n",
        "base_time = datetime.now()\n",
        "timestamps = [base_time - timedelta(minutes=random.randint(0, 60*24*90)) for _ in range(10000)]\n",
        "\n",
        "# Generate 10,000 fake lab feed posts\n",
        "lab_feed = []\n",
        "for i in range(10000):\n",
        "    post = {\n",
        "        'timestamp': timestamps[i],\n",
        "        'text': f\"{random.choice(people)} updated: {random.choice(topics)} progress at checkpoint {random.randint(1, 10)}.\"\n",
        "    }\n",
        "    lab_feed.append(post)\n",
        "\n",
        "# Convert to DataFrame\n",
        "lab_df = pd.DataFrame(lab_feed)\n",
        "lab_df['date'] = lab_df['timestamp'].dt.date\n",
        "lab_df['hour'] = lab_df['timestamp'].dt.hour\n",
        "\n",
        "print(\"=== Sample Lab Posts ===\")\n",
        "print(lab_df.head())\n",
        "\n",
        "# Filter posts with keyword 'protein'\n",
        "protein_posts = lab_df[lab_df['text'].str.contains('protein')]\n",
        "print(\"\\nTotal posts mentioning 'protein folding':\", len(protein_posts))\n",
        "\n",
        "# Posts per day\n",
        "print(\"\\n=== Posts per Day ===\")\n",
        "print(lab_df['date'].value_counts().sort_index().tail(10))\n",
        "\n",
        "# Most active hours\n",
        "print(\"\\n=== Most Active Posting Hours ===\")\n",
        "print(lab_df['hour'].value_counts().sort_index())\n",
        "\n",
        "# Word count stats\n",
        "lab_df['word_count'] = lab_df['text'].str.split().apply(len)\n",
        "print(\"\\nAverage words per post:\", lab_df['word_count'].mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eyI0kWrRxXZn",
        "outputId": "904bc0ea-c870-4b15-b7ff-e56d2aa3de45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sample Lab Posts ===\n",
            "                   timestamp  \\\n",
            "0 2025-08-14 15:39:04.184733   \n",
            "1 2025-08-23 02:45:04.184733   \n",
            "2 2025-09-25 05:21:04.184733   \n",
            "3 2025-09-04 07:29:04.184733   \n",
            "4 2025-08-04 15:46:04.184733   \n",
            "\n",
            "                                                text        date  hour  \n",
            "0  Ravi updated: experimental alignment progress ...  2025-08-14    15  \n",
            "1  Ravi updated: paper submission progress at che...  2025-08-23     2  \n",
            "2  Casey updated: paper submission progress at ch...  2025-09-25     5  \n",
            "3  Ravi updated: experimental alignment progress ...  2025-09-04     7  \n",
            "4  Casey updated: data cleanup progress at checkp...  2025-08-04    15  \n",
            "\n",
            "Total posts mentioning 'protein folding': 2026\n",
            "\n",
            "=== Posts per Day ===\n",
            "date\n",
            "2025-09-28    111\n",
            "2025-09-29    122\n",
            "2025-09-30    110\n",
            "2025-10-01    102\n",
            "2025-10-02    117\n",
            "2025-10-03     96\n",
            "2025-10-04    106\n",
            "2025-10-05    118\n",
            "2025-10-06    104\n",
            "2025-10-07     77\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Most Active Posting Hours ===\n",
            "hour\n",
            "0     432\n",
            "1     424\n",
            "2     407\n",
            "3     423\n",
            "4     427\n",
            "5     381\n",
            "6     447\n",
            "7     428\n",
            "8     434\n",
            "9     399\n",
            "10    435\n",
            "11    440\n",
            "12    428\n",
            "13    413\n",
            "14    402\n",
            "15    424\n",
            "16    385\n",
            "17    404\n",
            "18    421\n",
            "19    433\n",
            "20    407\n",
            "21    399\n",
            "22    406\n",
            "23    401\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Average words per post: 8.2012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# ## 8. Simulated Yelp API (Pizza Finder Business Search)\n",
        "# Local business APIs like Yelp and Google Places allow developers to query businesses by filters such as location,\n",
        "# rating, price, and category. These APIs return structured JSON that includes fields like `name`, `rating`,\n",
        "# `distance`, `price`, and `contact info`.\n",
        "# In this simulation, we generate 10,000 pizza shop records and show how to:\n",
        "# - Filter businesses by rating or price\n",
        "# - Sort results by distance (nearest)\n",
        "# - Analyze popular price points and average ratings\n",
        "# This mimics how ride-sharing, delivery, and restaurant apps use real-time location-aware business data.\n",
        "\n",
        "# %%\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Set up categories\n",
        "names = ['Tony’s Pizza', 'Mama’s Slice', 'Pizza Palace', 'Big Al’s Pies', 'Cheesy Bites', 'Neapolitan Express']\n",
        "price_levels = ['$', '$$', '$$$']\n",
        "area_codes = ['215', '610', '484', '267']\n",
        "\n",
        "# Generate 10,000 fake pizza shops\n",
        "pizza_shops = []\n",
        "for i in range(10000):\n",
        "    shop = {\n",
        "        'name': random.choice(names) + f\" #{random.randint(1, 500)}\",\n",
        "        'rating': round(random.uniform(2.5, 5.0), 1),\n",
        "        'review_count': random.randint(10, 1200),\n",
        "        'price': random.choices(price_levels, weights=[0.5, 0.4, 0.1])[0],\n",
        "        'distance_m': random.randint(100, 10000),\n",
        "        'phone': f\"+1-{random.choice(area_codes)}-{random.randint(100,999)}-{random.randint(1000,9999)}\"\n",
        "    }\n",
        "    pizza_shops.append(shop)\n",
        "\n",
        "# Load into DataFrame\n",
        "pizza_df = pd.DataFrame(pizza_shops)\n",
        "\n",
        "print(\"=== Sample Pizza Places ===\")\n",
        "print(pizza_df.head())\n",
        "\n",
        "# Filter: rating >= 4.5 and price <= $$\n",
        "top_picks = pizza_df[(pizza_df['rating'] >= 4.5) & (pizza_df['price'].isin(['$', '$$']))]\n",
        "print(f\"\\nTop Picks (rating ≥ 4.5 and $/$$): {len(top_picks)} places\")\n",
        "print(top_picks.sort_values('rating', ascending=False).head(5))\n",
        "\n",
        "# Closest shop\n",
        "print(\"\\nClosest pizza place:\")\n",
        "print(pizza_df.sort_values('distance_m').head(1))\n",
        "\n",
        "# Rating distribution\n",
        "print(\"\\n=== Rating Distribution ===\")\n",
        "print(pizza_df['rating'].value_counts().sort_index().tail(10))\n",
        "\n",
        "# Price level breakdown\n",
        "print(\"\\n=== Price Breakdown ===\")\n",
        "print(pizza_df['price'].value_counts())\n",
        "\n",
        "# Correlation: reviews vs. rating\n",
        "print(\"\\n=== Correlation: Review Count vs Rating ===\")\n",
        "print(pizza_df[['review_count', 'rating']].corr())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZDqSzkpexfHF",
        "outputId": "b58879a1-4b24-4231-a282-b6f603cbc415"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sample Pizza Places ===\n",
            "                      name  rating  review_count price  distance_m  \\\n",
            "0        Pizza Palace #354     3.6           276    $$        7481   \n",
            "1   Neapolitan Express #56     3.4           125     $        8351   \n",
            "2  Neapolitan Express #270     4.3          1169    $$        4872   \n",
            "3        Pizza Palace #112     4.1          1123   $$$        8789   \n",
            "4        Tony’s Pizza #162     3.3          1062   $$$        1306   \n",
            "\n",
            "             phone  \n",
            "0  +1-267-493-8346  \n",
            "1  +1-267-557-9614  \n",
            "2  +1-610-366-9403  \n",
            "3  +1-610-583-8798  \n",
            "4  +1-267-405-6992  \n",
            "\n",
            "Top Picks (rating ≥ 4.5 and $/$$): 1949 places\n",
            "                    name  rating  review_count price  distance_m  \\\n",
            "59    Big Al’s Pies #302     5.0          1137     $        2042   \n",
            "9999   Tony’s Pizza #148     5.0          1056    $$        3361   \n",
            "10     Mama’s Slice #322     5.0            84    $$        6118   \n",
            "2763   Big Al’s Pies #57     5.0            95    $$         796   \n",
            "2907    Pizza Palace #88     5.0           976     $        4487   \n",
            "\n",
            "                phone  \n",
            "59    +1-267-549-4058  \n",
            "9999  +1-610-553-1127  \n",
            "10    +1-484-706-5983  \n",
            "2763  +1-215-868-8742  \n",
            "2907  +1-484-658-5350  \n",
            "\n",
            "Closest pizza place:\n",
            "                   name  rating  review_count price  distance_m  \\\n",
            "1701  Tony’s Pizza #315     3.6           614     $         101   \n",
            "\n",
            "                phone  \n",
            "1701  +1-610-337-6392  \n",
            "\n",
            "=== Rating Distribution ===\n",
            "rating\n",
            "4.1    384\n",
            "4.2    389\n",
            "4.3    421\n",
            "4.4    424\n",
            "4.5    411\n",
            "4.6    378\n",
            "4.7    395\n",
            "4.8    392\n",
            "4.9    397\n",
            "5.0    191\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Price Breakdown ===\n",
            "price\n",
            "$      5046\n",
            "$$     3959\n",
            "$$$     995\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Correlation: Review Count vs Rating ===\n",
            "              review_count    rating\n",
            "review_count      1.000000 -0.011652\n",
            "rating           -0.011652  1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zstebbEAxnI-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}